
"Issue Id","Issue Type","Epic Name","Summary","Description","Parent","Module","Component","Execution Context","Acceptance Criteria","Story Points","Assignee","Reporter","Priority","Labels","Fix Versions","Sprint","Original Estimate","Remaining Estimate","Due Date","Attachment URL","External Id","Manifest Path","QA Status","Estimate Confidence"
"EPIC-SF-DG-MVP","Epic","Snowflake Document-Generation (MVP)","Snowflake backend for standalone Document‑Generation MVP","Implement Snowflake core DDL, ingestion, Snowpark stored procedures (billing preview + run), External Functions for similarity, FAISS index pipeline, provisioning, tests and CI so Document Generation can run as a standalone app.","","Snowflake","Platform","Snowflake (MVP)","All Snowflake artifacts applied, registered and passing smoke + deterministic tests in staging.","13","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","snowflake,mvp","v0.1-MVP","Sprint 1","14400","14400","","EPIC-SF-DG-MVP","manifest/snowflake/epics/EPIC-SF-DG-MVP","Planned","High"
"ST-SF-001","Story","Core DDL & Tables","Create core Snowflake DDL for Document Generation (tables + comments)","Create AI_PLATFORM.AI_FEATURE_HUB core DDL: DOCUMENT, TEMPLATE, CLAUSE, TENANT_FEATURE_USAGE, ACCOUNT_FEATURE_PRICING, BILLING_RUN, BILLING_LINE_ITEM, DOCUMENT_EMBEDDINGS, EVIDENCE_BUNDLE and associated comments and clustering keys.","EPIC-SF-DG-MVP","Snowflake","DDL","Snowflake","All core tables exist with required columns and comments; sample insert/read succeeds.","8","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","snowflake,ddl","v0.1-MVP","Sprint 1","14400","14400","","SFDG.SF.DDL.001","sql/core/ai_feature_hub_core_tables.sql","Planned","High"
"SUB-SF-001-01","Sub-task","Create DDL: DOCUMENT_ARCHIVE & EVIDENCE_BUNDLE","DDL: DOCUMENTARCHIVE and EVIDENCE_BUNDLE","Create DOCUMENTARCHIVE and EVIDENCE_BUNDLE tables with columns: DOCUMENTID, TEMPLATEID, ASSEMBLYRUNID, URL, HASH, CREATEDAT TIMESTAMPLTZ, CREATEDBY, JURISDICTION, RETENTIONTAG etc. Add table comments and clustering keys.","ST-SF-001","Snowflake","DDL","Snowflake","DDL deploys cleanly; example insert/read returns same values.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","snowflake,archive","v0.1-MVP","Sprint 1","7200","7200","","SFDG.SF.DDL.001.S1","sql/coreschema.sql; sql/evidence/","Planned","High"
"SUB-SF-001-02","Sub-task","Create DDL: EMBEDDINGS & VECTOR store","DDL: DOCUMENT_EMBEDDINGS and VECTOR store","Create DOCUMENT_EMBEDDINGS (document_id, embedding VARIANT/ARRAY, provenance, metadata) and VECTORSTORE table for optional Snowflake vectors; add comments and indexes/cluster keys.","ST-SF-001","Snowflake","DDL","Snowflake","Embeddings table created; sample vector insert/read OK.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","embeddings,vector","v0.1-MVP","Sprint 1","7200","7200","","SFDG.SF.DDL.001.S2","sql/vectorstore/schema.sql; sql/core/","Planned","High"
"ST-SF-002","Story","Staging + Snowpipe ingest","Create STAGE, FILE FORMAT and PIPE for embeddings & usage ingestion","Create FILE FORMAT for JSONL, user STAGE, and PIPE AUTO_INGEST to load embeddings/usage into STAGED_EMBEDDINGS / USAGE_EVENTS_STAGE; provide Cloud notifications guidance.","EPIC-SF-DG-MVP","Snowflake","Ingest","Snowflake","PUT to @~ then manual COPY and auto‑ingest via PIPE inserts rows into STAGED_ tables; SNOWPIPE notification config documented.","8","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","snowpipe,stage","v0.1-MVP","Sprint 1","14400","14400","","SFDG.SF.STAGE.002","sql/snowpipe_setup.sql; infra/snowflake_provisioning.py","Planned","High"
"SUB-SF-002-01","Sub-task","Create FILE FORMAT & STAGE","Create JSON FILE FORMAT and user_STAGE for embeddings","Implement CREATE FILE FORMAT and CREATE STAGE pointing to your S3 bucket with STORAGE_INTEGRATION.","ST-SF-002","Snowflake","FileFormat/Stage","Snowflake","Stage created and accessible; file format parses sample JSONL correctly.","3","onboarding@techkasetti.com","onboarding@techkasetti.com","High","fileformat,stage","v0.1-MVP","Sprint 1","3600","3600","","SFDG.SF.STAGE.002.S1","sql/snowpipe_setup.sql","Planned","High"
"SUB-SF-002-02","Sub-task","Create PIPE for auto-ingest","Create PIPE with AUTO_INGEST=TRUE to load into STAGED_EMBEDDINGS","Implement CREATE PIPE referencing the STAGE and FILE FORMAT; document required cloud notifications (SNS/SQS/Topic).","ST-SF-002","Snowflake","Pipe","Snowflake","PIPE ingests uploaded file to staging table when S3 notification fires; example ingest verified.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","High","pipe,snowpipe","v0.1-MVP","Sprint 1","7200","7200","","SFDG.SF.STAGE.002.S2","sql/snowpipe_setup.sql; infra/snowflake_provisioning.py","Planned","High"
"ST-SF-003","Story","Snowpark procedures (billing/ingest/entitlement)","Register and validate Snowpark stored procedures: run_billing_run (preview & final), entitlement_check, embedding_ingest_sp, ingest_usage_sp, write_evidence_bundle, generate_integration_key, validate_integration_key","Ensure all SPs are registered to AI_PLATFORM.AI_FEATURE_HUB and return the documented variants/structures for preview and auditability.","EPIC-SF-DG-MVP","Snowflake","Snowpark Procs","Snowpark (Python)","Stored procedures callable and preview returns line_items + invoice_hash identical to deterministic test; final run writes BILLING_RUN and BILLING_LINE_ITEM.","13","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","snowpark,proc,billing","v0.1-MVP","Sprint 1","28800","28800","","SFDG.SF.PROC.003","src/run_billing.py; src/entitlement_check.py; src/embedding_ingest_sp.py; src/ingest_usage_sp.py; src/write_evidence_bundle.py","Planned","High"
"SUB-SF-003-01","Sub-task","Register run_billing_run stored-proc","PUT run_billing.py to @~ and CREATE PROCEDURE ADMIN.RUN_BILLING_RUN(...)","Register stored-proc with IMPORTS pointing to @/run_billing.py and verify CALL returns preview JSON in staging.","ST-SF-003","Snowflake","Stored Proc","Snowpark","Procedure registered and CALL with preview=>TRUE returns expected JSON shape (line_items, invoice_hash).","8","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","proc,register","v0.1-MVP","Sprint 1","14400","14400","","SFDG.SF.PROC.003.S1","register/create_procedures_register.sql; register/register_all_procs.sh; infra/register_via_connector.py","Planned","High"
"SUB-SF-003-02","Sub-task","Register ingestion SPs (embedding_ingest_sp & ingest_usage_sp)","PUT embedding_ingest_sp.py & ingest_usage_sp.py to @ and CREATE PROCEDURE entries","Register idempotent ingestion stored-procs and run MERGE dry-run tests with sample staging file.","ST-SF-003","Snowflake","Stored Proc","Snowpark","Ingestion SPs registered; MERGE idempotency checks (duplicate idempotency_key) pass.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","ingest,merge","v0.1-MVP","Sprint 1","7200","7200","","SFDG.SF.PROC.003.S2","register/create_procedures_register.sql; src/embedding_ingest_sp.py; src/ingest_usage_sp.py","Planned","High"
"ST-SF-004","Story","Procedure registration (CI & fallback)","Provide registration scripts: register_all_procs.sh (snowsql) and register_via_connector.py (connector fallback)","Make registration runnable in CI using either snowsql or the Python connector and include idempotent create/replace semantics.","EPIC-SF-DG-MVP","Snowflake","Registration","DevOps/CI","Registration script runs end-to-end in CI and procedures are callable after script completes.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","ci,register","v0.1-MVP","Sprint 1","7200","7200","","SFDG.SF.REG.004","register/register_all_procs.sh; infra/register_via_connector.py; register/create_procedures_register.sql","Planned","High"
"SUB-SF-004-01","Sub-task","Implement register_all_procs.sh (snowsql)","Script to PUT Python files to @~ and execute CREATE PROCEDURE SQL using snowsql","Implement register_all_procs.sh with logging, error handling and overwrite semantics.","ST-SF-004","Snowflake","Registration Script","CI","Script runs successful PUT and CREATE PROCEDURE; logs captured in CI artifacts.","3","onboarding@techkasetti.com","onboarding@techkasetti.com","High","snowsql,script","v0.1-MVP","Sprint 1","3600","3600","","SFDG.SF.REG.004.S1","register/register_all_procs.sh","Planned","High"
"ST-SF-005","Story","External Functions & API_INTEGRATION","Register API_INTEGRATION and EXTERNAL FUNCTIONs for similarity and agent endpoints","Create API_INTEGRATION AI_FEATURE_HUB.ai_feature_integration and EXTERNAL FUNCTIONs SIMILARITY_QUERY and AGENT_RUN using your API gateway host/role ARN.","EPIC-SF-DG-MVP","Snowflake","External Functions","Snowflake","External functions created and example SELECT AI_FEATURE_HUB.SIMILARITY_QUERY(...) returns reachable JSON when container + gateway are up.","8","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","external-function,api","v0.1-MVP","Sprint 1","14400","14400","","SFDG.SF.EXTFN.005","sql/external_functions_register.sql; infra/snowflake_provisioning.py","Planned","High"
"SUB-SF-005-01","Sub-task","Create API_INTEGRATION record","SQL to CREATE API INTEGRATION with API_AWS_ROLE_ARN and allowed prefixes","Edit sql/external_functions_register.sql with API_AWS_ROLE_ARN and API gateway host, then execute as admin.","ST-SF-005","Snowflake","API Integration","Snowflake","API_INTEGRATION exists and SHOW INTEGRATIONS returns expected config.","3","onboarding@techkasetti.com","onboarding@techkasetti.com","High","api-integration","v0.1-MVP","Sprint 1","3600","3600","","SFDG.SF.EXTFN.005.S1","sql/external_functions_register.sql","Planned","High"
"ST-SF-006","Story","FAISS index builder & container (PoC for MVP)","Build FAISS index from Snowflake vectors and provide container skeleton to serve similarity queries","Extract vectors, build index file, upload to S3, produce manifest and Dockerfile for FAISS agent; document registry push & gateway config.","EPIC-SF-DG-MVP","Snowflake","ANN/FAISS","Infra","FAISS index uploaded to S3 and container registered behind API gateway returning top‑K results for sample query.","8","onboarding@techkasetti.com","onboarding@techkasetti.com","High","faiss,ann","v0.1-MVP","Sprint 2","14400","14400","","SFDG.SF.FAISS.006","faiss/production_faiss_builder_v2.py; faiss/Dockerfile; infra/deploy_faiss_snapshot.sh","Planned","High"
"SUB-SF-006-01","Sub-task","Build FAISS index & upload to S3","Run production_faiss_builder_v2.py with Snowflake creds and S3 target","Fetch embeddings with SQL, build IndexFlatL2 (or IVF per scale) and upload index file to S3; produce faiss_manifest.json.","ST-SF-006","Snowflake","FAISS Builder","Infra","S3 contains index file and manifest.json; sample query against container returns expected ids.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","High","faiss,upload","v0.1-MVP","Sprint 2","7200","7200","","SFDG.SF.FAISS.006.S1","faiss/production_faiss_builder_v2.py","Planned","High"
"ST-SF-007","Story","Masking, Row Policies & Grants","Create masking policy(s), row access policy(s) and initial GRANTs for service roles","Create MASKING POLICY for provenance fields and ROW ACCESS POLICY skeleton; apply to columns and grant least privilege to SERVICE_ROLE.","EPIC-SF-DG-MVP","Snowflake","Security","Snowflake","Policies created and applied; queries as non‑privileged roles see masked values or denied rows as designed.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","High","policy,grants","v0.1-MVP","Sprint 2","7200","7200","","SFDG.SF.SEC.007","sql/attach_policies_and_grants.sql; infra/snowflake_provisioning.py","Planned","High"
"SUB-SF-007-01","Sub-task","Create & attach MASKING policy","Create masking policy and attach to DOCUMENT_EMBEDDINGS.provenance_id","Execute sql/attach_policies_and_grants.sql after reviewing role names; verify masking behavior with sample queries under different roles.","ST-SF-007","Snowflake","Masking","Snowflake","Masked value returned for unprivileged role and full value for compliance/admin role.","3","onboarding@techkasetti.com","onboarding@techkasetti.com","High","masking,pii","v0.1-MVP","Sprint 2","3600","3600","","SFDG.SF.SEC.007.S1","sql/attach_policies_and_grants.sql","Planned","High"
"ST-SF-008","Story","Deterministic billing tests & smoke harness","Implement deterministic test (pytest) + smoke shell script to validate ingestion→entitlement→billing preview path","Provide tests/test_deterministic_billing.py and tests/smoke/full_acceptance_smoke.sh that assert invoice_hash and line_items.","EPIC-SF-DG-MVP","Snowflake","Tests","CI/Dev","pytest deterministic test passes; smoke harness returns success and DB rows persisted as expected.","8","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","tests,smoke","v0.1-MVP","Sprint 1","14400","14400","","SFDG.SF.TEST.008","tests/test_deterministic_billing.py; tests/smoke/full_acceptance_smoke.sh; tests/sql/billing_unit_tests_extended.sql","Planned","High"
"SUB-SF-008-01","Sub-task","Implement deterministic pytest test","Add tests/test_deterministic_billing.py that seeds a deterministic fixture and asserts invoice_hash exactly","Use canonical JSON serialization + sha256 to compute expected invoice_hash locally and compare to SP output.","ST-SF-008","Snowflake","Unit Test","CI","Deterministic test returns PASS in CI and locally with SNOW_* creds set.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","pytest,billing","v0.1-MVP","Sprint 1","7200","7200","","SFDG.SF.TEST.008.S1","tests/test_deterministic_billing.py","Planned","High"
"ST-SF-009","Story","CI Workflow","Add CI workflow to register procs, deploy DDL, run smoke & run deterministic tests","Create .github/workflows/ci.yml to execute registration, DDL deploy and tests in order; upload logs as artifacts.","EPIC-SF-DG-MVP","Snowflake","CI","GitHub Actions","CI run completes registration + smoke + pytest with artifacts attached; failures block merge.","5","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","ci,github","v0.1-MVP","Sprint 1","7200","7200","","SFDG.SF.CI.009",".github/workflows/ci.yml","Planned","High"
"ST-SF-010","Story","Deploy & smoke runbook & ordered deploy script","Create deploy script that stages Python files to @~ and runs CREATE TABLE/CREATE PROCEDURE in safe order, and provide smoke queries","Provide a single deploy script that executes DDL then registers procs then runs smoke checks and deterministic test.","EPIC-SF-DG-MVP","Snowflake","Deploy","Ops","Deploy script runs in sequence and smoke checks succeed; rollbacks documented.","8","onboarding@techkasetti.com","onboarding@techkasetti.com","Highest","deploy,runbook","v0.1-MVP","Sprint 1","14400","14400","","SFDG.SF.DEPLOY.010","deploy/deploy_snowflake_procs.sh; infra/register_via_connector.py; tests/smoke/","Planned","High"